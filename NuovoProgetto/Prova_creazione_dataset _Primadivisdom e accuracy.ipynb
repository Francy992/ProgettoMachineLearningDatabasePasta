{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variabilil globali\n",
    "width = 256\n",
    "height = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AlexNet import *\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from PIL import Image\n",
    "from os import path\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "np.random.seed(1234)\n",
    "torch.random.manual_seed(1234);\n",
    "\n",
    "class ScenesDataset(Dataset):\n",
    "    def __init__(self,base_path,txt_list,transform=None):\n",
    "        #conserviamo il path alla cartella contenente le immagini\n",
    "        self.base_path=base_path\n",
    "        #carichiamo la lista dei file\n",
    "        #sarà una matrice con n righe (numero di immagini) e 2 colonne (path, etichetta)\n",
    "        self.images = np.loadtxt(txt_list,dtype=str,delimiter=',')\n",
    "        #print(\"self.images ha i seguenti elementi:\", len(self.images))\n",
    "        #conserviamo il riferimento alla trasformazione da applicare\n",
    "        self.transform = transform\n",
    "    def __getitem__(self, index):\n",
    "        #print(\"Get item numero -->\", index)\n",
    "        #recuperiamo il path dell'immagine di indice index e la relativa etichetta\n",
    "        f,c = self.images[index]\n",
    "        #carichiamo l'immagine utilizzando PIL e facciamo il resize a 3 canali.\n",
    "        im = Image.open(path.join(self.base_path, f)).convert(\"RGB\")\n",
    "        \n",
    "        #Resize:\n",
    "        im = im.resize((width,height))\n",
    "        #se la trasfromazione è definita, applichiamola all'immagine\n",
    "        if self.transform is not None:\n",
    "            im = self.transform(im)\n",
    "        \n",
    "        \n",
    "        #convertiamo l'etichetta in un intero\n",
    "        label = int(c)\n",
    "        #restituiamo un dizionario contenente immagine etichetta\n",
    "        #print(\"Mentre creo il tutto, label vale-->\", label, \", name vale -->\", f)\n",
    "        return {'image' : im, 'label':label, 'name': f}\n",
    "    #restituisce il numero di campioni: la lunghezza della lista \"images\"\n",
    "    def __len__(self):\n",
    "        #print(\"Ho invocato len, vale-->\", len(self.images))\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = ScenesDataset('Dataset','train.txt',transform=transforms.ToTensor())\n",
    "#for i in range(0, len(dataset)):\n",
    "    #print(dataset[i]['image'].shape, dataset[i]['label'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizziamo i dati:\n",
    "#dataset = ScenesDataset('8scenes','8scenes/train.txt',transform=transforms.ToTensor())\n",
    "m = np.zeros(3)\n",
    "for sample in dataset:\n",
    "    m+= np.array(sample['image'].sum(1).sum(1)) #accumuliamo la somma dei pixel canale per canale\n",
    "#dividiamo per il numero di immagini moltiplicato per il numero di pixel\n",
    "m=m/(len(dataset)*width*height)\n",
    "#procedura simile per calcolare la deviazione standard\n",
    "s = np.zeros(3)\n",
    "for sample in dataset:\n",
    "    s+= np.array(((sample['image']-torch.Tensor(m).view(3,1,1))**2).sum(1).sum(1))\n",
    "s=np.sqrt(s/(len(dataset)*width*height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medie [0.53432863 0.50716533 0.5028028 ]\n",
      "Dev.Std. [0.35351087 0.32069801 0.2918144 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Medie\",m)\n",
    "print(\"Dev.Std.\",s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Per evitare di  ricalcolare nuovamente le medie provare a salvarle qui.\n",
    "#Medie [0.53426401 0.5071057  0.50278591]\n",
    "#Dev.Std. [0.35348395 0.32069717 0.29183253]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transformss = transforms.Compose([transforms.ToTensor(), transforms.Normalize(m,s)])\n",
    "\n",
    "barilla_train = ScenesDataset('Dataset','train.txt',transform=transformss)\n",
    "barilla_test = ScenesDataset('Dataset','test.txt',transform=transformss)\n",
    "print()\n",
    "barilla_train_loader = torch.utils.data.DataLoader(barilla_train, batch_size=1, num_workers=0, shuffle=True)\n",
    "barilla_test_loader = torch.utils.data.DataLoader(barilla_test, batch_size=1, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57626584"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = AlexNet()\n",
    "sum([p.numel() for p in net.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from torch.optim import SGD\n",
    "from torch.autograd import Variable\n",
    "def train_classification(model, train_loader, test_loader, lr=0.01, epochs=20, momentum=0.9):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = SGD(model.parameters(),lr, momentum=momentum)\n",
    "    loaders = {'train':train_loader, 'test':test_loader}\n",
    "    losses = {'train':[], 'test':[]}\n",
    "    accuracies = {'train':[], 'test':[]}\n",
    "    if torch.cuda.is_available():\n",
    "        model=model.cuda()\n",
    "    for e in range(epochs):\n",
    "        #print(\"Primo ciclo for.\")\n",
    "        for mode in ['train', 'test']:\n",
    "            #print(\"Secondo ciclo for.\")\n",
    "            if mode=='train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            epoch_loss = 0\n",
    "            epoch_acc = 0\n",
    "            samples = 0\n",
    "            #print(\"Mode-->\",mode)\n",
    "            #print(\"Enumerate-->\", loaders[mode])\n",
    "            for i, batch in enumerate(loaders[mode]):\n",
    "                #trasformiamo i tensori in variabili\n",
    "                x=Variable(batch['image'], requires_grad=(mode=='train'))\n",
    "                y=Variable(batch['label'])\n",
    "                if torch.cuda.is_available():\n",
    "                    x, y = x.cuda(), y.cuda()\n",
    "                    print(\"Con cuda\")\n",
    "                #else:\n",
    "                    #print(\"Senza cuda\")\n",
    "                output = model(x)\n",
    "                #print(type(output))\n",
    "                #print(output)\n",
    "                l = criterion(output,y)\n",
    "                if mode=='train':\n",
    "                    l.backward()\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                #print(\"L-->\",l.item())\n",
    "                acc = accuracy_score(y.cpu().data,output.cpu().max(1)[1].data)\n",
    "                epoch_loss+=l.data.item()*x.shape[0]\n",
    "                epoch_acc+=acc*x.shape[0]\n",
    "                samples+=x.shape[0]\n",
    "                print (\"\\r[%s] Epoch %d/%d. Iteration %d/%d. Loss: %0.2f. Accuracy: %0.2f\\t\\t\\t\\t\\t\" % \\\n",
    "                (mode, e+1, epochs, i, len(loaders[mode]), epoch_loss/samples, epoch_acc/samples),\n",
    "                epoch_loss/samples,\n",
    "                epoch_acc/samples,\n",
    "                losses[mode].append(epoch_loss))\n",
    "                accuracies[mode].append(epoch_acc)\n",
    "            #print(\"Fine secondo ciclo for\")\n",
    "        print(\"\\r[%s] Epoch %d/%d. Iteration %d/%d. Loss: %0.2f. Accuracy: %0.2f\\t\\t\\t\\t\\t\" % \\\n",
    "        (mode, e+1, epochs, i, len(loaders[mode]), epoch_loss, epoch_acc))\n",
    "\n",
    "    print(\"Ho finito.\")\n",
    "    #restituiamo il modello e i vari log\n",
    "    return model, (losses, accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Con nostro dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 0/302. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.02742862701416 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 1/302. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.020767688751221 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 2/302. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.021445274353027 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 3/302. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.025376915931702 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 4/302. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026198768615723 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 5/302. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.023585081100464 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 6/302. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026035240718296 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 7/302. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.029059708118439 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 8/302. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.0278622839185925 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 9/302. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.027604818344116 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 10/302. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.027980804443359 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 11/302. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.027445395787557 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 12/302. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.028411058279184 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 13/302. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.029881375176566 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 14/302. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.031744384765625 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 15/302. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.0235492289066315 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 16/302. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.0247299250434425 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 17/302. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.025121291478475 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 18/302. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.0273646806415755 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 19/302. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.027149987220764 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 20/302. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.029735179174514 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 21/302. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.030883117155596 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 22/302. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.031517878822658 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 23/302. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.024534126122792 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 24/302. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026452388763428 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 25/302. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.028366969181941 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 26/302. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.029564274681939 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 27/302. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.032454524721418 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 28/302. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.032743700619402 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 29/302. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.034172916412354 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 30/302. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.028213285630749 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 31/302. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.029827892780304 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 32/302. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.02963129679362 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 33/302. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.0310971596661735 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 34/302. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.032476779392788 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 35/302. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.033889373143514 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 36/302. Loss: 5.04. Accuracy: 0.00\t\t\t\t\t 5.035282972696665 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 37/302. Loss: 5.04. Accuracy: 0.00\t\t\t\t\t 5.035961715798629 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 38/302. Loss: 5.04. Accuracy: 0.00\t\t\t\t\t 5.036534468332927 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 39/302. Loss: 5.04. Accuracy: 0.00\t\t\t\t\t 5.0375435709953305 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 40/302. Loss: 5.04. Accuracy: 0.00\t\t\t\t\t 5.03888408149161 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 41/302. Loss: 5.04. Accuracy: 0.00\t\t\t\t\t 5.039950450261434 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 42/302. Loss: 5.04. Accuracy: 0.00\t\t\t\t\t 5.04056270732436 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 43/302. Loss: 5.04. Accuracy: 0.00\t\t\t\t\t 5.041141444986517 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 44/302. Loss: 5.04. Accuracy: 0.00\t\t\t\t\t 5.04173206753201 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 45/302. Loss: 5.04. Accuracy: 0.00\t\t\t\t\t 5.042526120724886 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 46/302. Loss: 5.04. Accuracy: 0.00\t\t\t\t\t 5.04323540342615 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 47/302. Loss: 5.04. Accuracy: 0.00\t\t\t\t\t 5.043741414944331 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 48/302. Loss: 5.04. Accuracy: 0.00\t\t\t\t\t 5.0444062777927945 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 49/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.045031003952026 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 50/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.045689601524203 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 51/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.046223264474135 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 52/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.046718291516574 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 53/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.046991224642153 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 54/302. Loss: 5.04. Accuracy: 0.00\t\t\t\t\t 5.044495513222435 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 55/302. Loss: 5.04. Accuracy: 0.00\t\t\t\t\t 5.044998390333993 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 56/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.0456951040970655 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 57/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.045956389657382 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 58/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.04642362917884 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 59/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.047088750203451 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 60/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.0474799343797025 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 61/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.047880803385088 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 62/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.046503218393477 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 63/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.046825885772705 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 64/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.047168746361366 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 65/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.047607118433172 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 66/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.047138043303988 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 67/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.046935165629668 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 68/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.046869768612627 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 69/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.047238152367728 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 70/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.047720606897919 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 71/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.048193335533142 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 72/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.048831345283822 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 73/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.049272479237737 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 74/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.049963308970134 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 75/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.050693179431715 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 76/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.051234412502933 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 77/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.049639457311386 0.0 None\n",
      "Con cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch 1/1. Iteration 78/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.050089721438251 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 79/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.0505598247051235 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 80/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.051260524325901 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 81/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.050713480972663 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 82/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.0512524915028765 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 83/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.049912560553778 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 84/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.050381666071274 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 85/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.04944893925689 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 86/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.050036375550018 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 87/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.0491064895283095 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 88/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.048068046569824 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 89/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.048701943291558 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 90/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.049204590556386 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 91/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.04964744526407 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 92/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.050201938998315 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 93/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.050583971307633 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 94/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.050962533448872 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 95/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.0513772666454315 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 96/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.05026540068007 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 97/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.050835030419486 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 98/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.05003185946532 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 99/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.050651988983154 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 100/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.051140889082805 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 101/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.051798661549886 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 102/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.052233964494131 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 103/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.052867201658396 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 104/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.052289372398739 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 105/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.052736340828662 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 106/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.053256440385479 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 107/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.0536883804533215 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 108/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.054216240524152 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 109/302. Loss: 5.05. Accuracy: 0.00\t\t\t\t\t 5.0546548106453635 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 110/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.055241649215286 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 111/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.055642362151827 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 112/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.056061322710155 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 113/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.056513945261638 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 114/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.056964310355808 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 115/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.05748881964848 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 116/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.057993354960384 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 117/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.0585037974988 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 118/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.058102138903963 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 119/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.057511035601298 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 120/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.056953729676806 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 121/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.057544618356423 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 122/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.057975148766991 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 123/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.0583897636782735 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 124/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.058866130828857 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 125/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.058387760132078 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 126/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.058015560540627 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 127/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.0585699044167995 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 128/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.0591477497603545 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 129/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.05976714354295 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 130/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.059311601041838 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 131/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.059209400957281 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 132/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.059761552882374 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 133/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.06023325137238 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 134/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.060662107114439 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 135/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.061236423604629 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 136/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.061739044467898 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 137/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.0613949264305225 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 138/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.061833162101911 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 139/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.062217848641532 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 140/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.062619344562504 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 141/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.062238213042138 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 142/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.061801096776149 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 143/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.062275939517551 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 144/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.062776009789829 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 145/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.063134030120014 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 146/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.062829166853509 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 147/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.063160532229656 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 148/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.06280771997951 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 149/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.062545925776163 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 150/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.0629697951259995 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 151/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.0626793284165235 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 152/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.063191572825114 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 153/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.063001561474491 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 154/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.063470782003095 0.0 None\n",
      "Con cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch 1/1. Iteration 155/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.0640155382645435 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 156/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.063798570329217 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 157/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.063624119456811 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 158/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.063280642407495 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 159/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.063694363832473 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 160/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.063545656500396 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 161/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.0633204424822775 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 162/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.063740490404375 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 163/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.064146669899545 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 164/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.063994055083303 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 165/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.063757129462369 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 166/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.063647247360138 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 167/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.063392710118067 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 168/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.063226090380426 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 169/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.0636670729693245 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 170/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.064160935362877 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 171/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.064667635185774 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 172/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.064610492287343 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 173/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.064484692167961 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 174/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.064214019775391 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 175/302. Loss: 5.06. Accuracy: 0.00\t\t\t\t\t 5.064692749218508 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 176/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.065185220901576 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 177/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.0656313360407115 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 178/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.066125811145293 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 179/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.0659272220399645 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 180/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.065778360841024 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 181/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.065663481806661 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 182/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.065565218690966 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 183/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.0660407595012495 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 184/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.066434375659839 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 185/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.0663742352557435 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 186/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.066860538115476 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 187/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.066833161293192 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 188/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.067262021322099 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 189/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.067188252900776 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 190/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.067043401808014 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 191/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.067511280377706 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 192/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.067927909020933 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 193/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.067769468445139 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 194/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.067651533469176 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 195/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.067771364231499 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 196/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.067718847148915 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 197/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.067589177025689 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 198/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.067487469869643 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 199/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.067369358539581 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 200/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.067311215756544 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 201/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.067780253910782 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 202/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.068163465396524 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 203/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.068077861094007 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 204/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.06801290046878 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 205/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.068017563773591 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 206/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.068531075537493 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 207/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.068448293667573 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 208/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.068454372825805 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 209/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.068474681036813 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 210/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.068422242928455 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 211/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.068383135885562 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 212/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.068401831416457 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 213/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.068843694490807 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 214/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.069312743253486 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 215/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.069222222875665 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 216/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.06923397345477 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 217/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.06916799457795 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 218/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.069118771923187 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 219/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.06908934766596 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 220/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.069513575523687 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 221/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.069511344840935 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 222/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.069534169184253 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 223/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.069942408374378 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 224/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.069930027855767 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 225/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.069952203109201 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 226/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.070010647374628 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 227/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.0700295975333765 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 228/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.069985510480456 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 229/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.070033361600793 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 230/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.070442106816675 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 231/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.070437566987399 0.0 None\n",
      "Con cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch 1/1. Iteration 232/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.070508602862706 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 233/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.070529766571828 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 234/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.070617730566796 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 235/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.070734189728559 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 236/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.070773382227129 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 237/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.070829706031735 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 238/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.070865461517078 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 239/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.0709002415339155 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 240/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.070921755430609 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 241/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.070938210842038 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 242/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.0709813102282615 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 243/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.07102047810789 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 244/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.07099497269611 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 245/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.071037746057278 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 246/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.0710310955279265 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 247/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.071053081943143 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 248/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.071111857172954 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 249/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.071522863388061 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 250/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.071609932112978 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 251/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.071593269469246 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 252/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.071971035757555 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 253/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.071988734673328 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 254/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.0720850252637675 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 255/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.072148870676756 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 256/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.072209085471899 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 257/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.07222993429317 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 258/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.072696704201717 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 259/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.072720978810237 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 260/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.072852143839401 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 261/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.072973999358315 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 262/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.073088323208769 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 263/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.0732052163644275 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 264/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.073309669854506 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 265/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.073418774999174 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 266/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.073839628741089 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 267/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.073959403963231 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 268/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.074006156850482 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 269/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.074110486772326 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 270/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.0741992964515825 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 271/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.07426667914671 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 272/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.074386027269748 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 273/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.074472761502231 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 274/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.074582229961049 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 275/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.074710420940233 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 276/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.074734727398153 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 277/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.074789970041179 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 278/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.074814743465847 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 279/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.074921371255602 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 280/302. Loss: 5.07. Accuracy: 0.00\t\t\t\t\t 5.074971002191836 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 281/302. Loss: 5.08. Accuracy: 0.00\t\t\t\t\t 5.07503145975424 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 282/302. Loss: 5.08. Accuracy: 0.00\t\t\t\t\t 5.075160958320429 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 283/302. Loss: 5.08. Accuracy: 0.00\t\t\t\t\t 5.075263239967991 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 284/302. Loss: 5.08. Accuracy: 0.00\t\t\t\t\t 5.075326827534458 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 285/302. Loss: 5.08. Accuracy: 0.00\t\t\t\t\t 5.07541484099168 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 286/302. Loss: 5.08. Accuracy: 0.00\t\t\t\t\t 5.0755171078007395 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 287/302. Loss: 5.08. Accuracy: 0.00\t\t\t\t\t 5.075653612613678 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 288/302. Loss: 5.08. Accuracy: 0.00\t\t\t\t\t 5.075743406289177 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 289/302. Loss: 5.08. Accuracy: 0.00\t\t\t\t\t 5.075906830820544 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 290/302. Loss: 5.08. Accuracy: 0.00\t\t\t\t\t 5.07601226400264 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 291/302. Loss: 5.08. Accuracy: 0.00\t\t\t\t\t 5.076117277145386 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 292/302. Loss: 5.08. Accuracy: 0.00\t\t\t\t\t 5.076223467804059 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 293/302. Loss: 5.08. Accuracy: 0.00\t\t\t\t\t 5.076303764265411 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 294/302. Loss: 5.08. Accuracy: 0.00\t\t\t\t\t 5.076396167884439 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 295/302. Loss: 5.08. Accuracy: 0.00\t\t\t\t\t 5.076466768174558 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 296/302. Loss: 5.08. Accuracy: 0.00\t\t\t\t\t 5.076501732322102 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 297/302. Loss: 5.08. Accuracy: 0.00\t\t\t\t\t 5.076564233575091 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 298/302. Loss: 5.08. Accuracy: 0.00\t\t\t\t\t 5.0766661924662 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 299/302. Loss: 5.08. Accuracy: 0.00\t\t\t\t\t 5.076771901448567 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 300/302. Loss: 5.08. Accuracy: 0.00\t\t\t\t\t 5.07689749283648 0.0 None\n",
      "Con cuda\n",
      "[train] Epoch 1/1. Iteration 301/302. Loss: 5.08. Accuracy: 0.00\t\t\t\t\t 5.077031508186795 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 0/152. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.015613079071045 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 1/152. Loss: 5.04. Accuracy: 0.00\t\t\t\t\t 5.035578966140747 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 2/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.030954519907634 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 3/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.027282357215881 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 4/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026822280883789 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 5/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.025867144266765 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 6/152. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.024999618530273 0.0 None\n",
      "Con cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch 1/1. Iteration 7/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.025314807891846 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 8/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.025743749406603 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 9/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.027627944946289 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 10/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026202895424583 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 11/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.025981585184733 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 12/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.025661065028264 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 13/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.032203606196812 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 14/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.031043529510498 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 15/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.029719740152359 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 16/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.029508310205796 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 17/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.028780115975274 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 18/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.028167046998677 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 19/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.02772536277771 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 20/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.027471882956369 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 21/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.0275586084886035 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 22/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.0268913973932685 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 23/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026756107807159 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 24/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.025979747772217 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 25/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.025282162886399 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 26/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.0252634684244795 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 27/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026055932044983 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 28/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.025730971632333 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 29/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.025348933537801 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 30/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026087376379198 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 31/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.027553588151932 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 32/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.02781867980957 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 33/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.027202774496639 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 34/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026982007707868 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 35/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.0271786318884955 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 36/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.0265997036083325 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 37/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026558449393825 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 38/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.02627777441954 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 39/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.028304040431976 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 40/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.028109678407994 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 41/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.027729272842407 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 42/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.027794405471447 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 43/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.027750643816861 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 44/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.027955214182536 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 45/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.027656845424486 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 46/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.027511606825159 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 47/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.027187317609787 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 48/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.027138379155373 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 49/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026843242645263 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 50/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.027165384853587 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 51/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026692335422222 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 52/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026590716164067 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 53/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.027066168961702 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 54/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.027069083127109 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 55/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.0268436414854865 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 56/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026734435767458 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 57/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026458756677036 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 58/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026399378049171 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 59/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.0261865456899 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 60/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026196745575452 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 61/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026501840160739 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 62/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.02636476546999 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 63/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026388414204121 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 64/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.0263284609867975 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 65/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026468854961974 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 66/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026685010141401 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 67/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026769364581389 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 68/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026593284330506 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 69/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026397487095424 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 70/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.02654788863491 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 71/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026239064004686 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 72/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026115502396675 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 73/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026131327087815 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 74/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026309121449788 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 75/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026161777345758 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 76/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026316791385799 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 77/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026295967591115 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 78/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.025985802276225 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 79/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.026002925634384 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 80/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.0257757622518655 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 81/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.02571112935136 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 82/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.025586277605539 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 83/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.025630258378529 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 84/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.025592186871697 0.0 None\n",
      "Con cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch 1/1. Iteration 85/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.025324721669042 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 86/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.0255565698119415 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 87/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.025543483820829 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 88/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.025582661789454 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 89/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.02538423008389 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 90/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.0254801498664605 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 91/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.0253496947495835 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 92/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.0253186841164865 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 93/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.025316700022271 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 94/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.025286062140214 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 95/152. Loss: 5.03. Accuracy: 0.00\t\t\t\t\t 5.025170008341472 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 96/152. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.024908365662565 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 97/152. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.024645766433404 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 98/152. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.02447808390916 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 99/152. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.0243612575531005 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 100/152. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.024363824636629 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 101/152. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.024285639033598 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 102/152. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.024210133598846 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 103/152. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.02397588124642 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 104/152. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.023940004621234 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 105/152. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.0239442564406485 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 106/152. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.023969320493324 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 107/152. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.023805035485162 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 108/152. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.023797774533613 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 109/152. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.024017303640192 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 110/152. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.023895134796968 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 111/152. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.023773116724832 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 112/152. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.0239011165315075 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 113/152. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.023813322970741 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 114/152. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.023998148544975 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 115/152. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.023843633717504 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 116/152. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.024460173060751 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 117/152. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.024619918758586 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 118/152. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.02459929169727 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 119/152. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.024542494614919 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 120/152. Loss: 5.02. Accuracy: 0.00\t\t\t\t\t 5.024601644720913 0.0 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 121/152. Loss: 5.02. Accuracy: 0.01\t\t\t\t\t 5.024357877793859 0.00819672131147541 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 122/152. Loss: 5.02. Accuracy: 0.01\t\t\t\t\t 5.024338253145295 0.008130081300813009 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 123/152. Loss: 5.02. Accuracy: 0.01\t\t\t\t\t 5.02417621689458 0.008064516129032258 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 124/152. Loss: 5.02. Accuracy: 0.01\t\t\t\t\t 5.024123390197754 0.008 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 125/152. Loss: 5.02. Accuracy: 0.01\t\t\t\t\t 5.024125458702208 0.007936507936507936 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 126/152. Loss: 5.02. Accuracy: 0.01\t\t\t\t\t 5.024574253502793 0.007874015748031496 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 127/152. Loss: 5.02. Accuracy: 0.01\t\t\t\t\t 5.024531818926334 0.0078125 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 128/152. Loss: 5.03. Accuracy: 0.01\t\t\t\t\t 5.025189277737639 0.007751937984496124 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 129/152. Loss: 5.03. Accuracy: 0.01\t\t\t\t\t 5.025183629989624 0.007692307692307693 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 130/152. Loss: 5.03. Accuracy: 0.01\t\t\t\t\t 5.025054665922209 0.007633587786259542 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 131/152. Loss: 5.03. Accuracy: 0.01\t\t\t\t\t 5.025089524009011 0.007575757575757576 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 132/152. Loss: 5.03. Accuracy: 0.01\t\t\t\t\t 5.025096473837257 0.007518796992481203 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 133/152. Loss: 5.03. Accuracy: 0.01\t\t\t\t\t 5.0250039029477245 0.007462686567164179 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 134/152. Loss: 5.03. Accuracy: 0.01\t\t\t\t\t 5.02503429695412 0.007407407407407408 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 135/152. Loss: 5.03. Accuracy: 0.01\t\t\t\t\t 5.025138609549579 0.007352941176470588 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 136/152. Loss: 5.03. Accuracy: 0.01\t\t\t\t\t 5.025163859346487 0.0072992700729927005 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 137/152. Loss: 5.03. Accuracy: 0.01\t\t\t\t\t 5.025225069211877 0.007246376811594203 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 138/152. Loss: 5.03. Accuracy: 0.01\t\t\t\t\t 5.025085480093098 0.007194244604316547 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 139/152. Loss: 5.02. Accuracy: 0.01\t\t\t\t\t 5.024892050879342 0.007142857142857143 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 140/152. Loss: 5.02. Accuracy: 0.01\t\t\t\t\t 5.024854900143671 0.0070921985815602835 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 141/152. Loss: 5.02. Accuracy: 0.01\t\t\t\t\t 5.024697471672381 0.007042253521126761 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 142/152. Loss: 5.02. Accuracy: 0.01\t\t\t\t\t 5.0246026932776395 0.006993006993006993 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 143/152. Loss: 5.02. Accuracy: 0.01\t\t\t\t\t 5.024694187773599 0.006944444444444444 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 144/152. Loss: 5.02. Accuracy: 0.01\t\t\t\t\t 5.0245350278657055 0.006896551724137931 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 145/152. Loss: 5.02. Accuracy: 0.01\t\t\t\t\t 5.024564400111159 0.00684931506849315 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 146/152. Loss: 5.02. Accuracy: 0.01\t\t\t\t\t 5.024417371165995 0.006802721088435374 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 147/152. Loss: 5.02. Accuracy: 0.01\t\t\t\t\t 5.024224329639125 0.006756756756756757 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 148/152. Loss: 5.02. Accuracy: 0.01\t\t\t\t\t 5.024129441920543 0.006711409395973154 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 149/152. Loss: 5.02. Accuracy: 0.01\t\t\t\t\t 5.024081885019938 0.006666666666666667 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 150/152. Loss: 5.02. Accuracy: 0.01\t\t\t\t\t 5.02405231362147 0.006622516556291391 None\n",
      "Con cuda\n",
      "[test] Epoch 1/1. Iteration 151/152. Loss: 5.02. Accuracy: 0.01\t\t\t\t\t 5.024063078980697 0.006578947368421052 None\n",
      "[test] Epoch 1/1. Iteration 151/152. Loss: 763.66. Accuracy: 1.00\t\t\t\t\t\n",
      "Ho finito.\n"
     ]
    }
   ],
   "source": [
    "lenet_mnist, lenet_mnist_logs = train_classification(net, epochs=1, train_loader = barilla_train_loader,\n",
    "                                                     test_loader = barilla_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def plot_logs_classification(logs):\n",
    "    training_losses, training_accuracies, test_losses, test_accuracies = \\\n",
    "    logs[0]['train'], logs[1]['train'], logs[0]['test'], logs[1]['test']\n",
    "    plt.figure(figsize=(18,6))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(training_losses)\n",
    "    plt.plot(test_losses)\n",
    "    plt.legend(['Training Loss','Test Losses'])\n",
    "    plt.grid()\n",
    "    plt.subplot(122)\n",
    "    plt.plot(training_accuracies)\n",
    "    plt.plot(test_accuracies)\n",
    "    plt.legend(['Training Accuracy','Test Accuracy'])\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18132029a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_logs_classification(lenet_mnist_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def test_model_classification(model, test_loader = barilla_test_loader):\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    gts = []\n",
    "    for batch in test_loader:\n",
    "        x=Variable(batch[\"image\"])\n",
    "        #applichiamo la funzione softmax per avere delle probabilità\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "        pred = softmax(model(x)).data.cpu().numpy().copy()\n",
    "        gt = batch[\"label\"].cpu().numpy().copy()\n",
    "        #print(\"Pred-->\", pred, \", gt-->\", gt)\n",
    "        preds.append(pred)\n",
    "        gts.append(gt)\n",
    "        #print(len(preds), len(gts))\n",
    "    return np.concatenate(preds),np.concatenate(gts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy LeNet su DIGITS: 0.01\n"
     ]
    }
   ],
   "source": [
    "lenet_mnist_predictions, lenet_mnist_gt = test_model_classification(net)\n",
    "print (\"Accuracy LeNet su DIGITS: %0.2f\" % \\\n",
    "accuracy_score(lenet_mnist_gt,lenet_mnist_predictions.argmax(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creazione feature dataset di training e test set\n",
    "def GetInputForDataframe(dataset, net):\n",
    "    #Presa ogni riga del dataloader li passa alla net senza attivare il layer di classificazione\n",
    "    feature_dataset = []\n",
    "    for i, dataset_train in enumerate(dataset):\n",
    "        #print(i, \"-->\",dataset_train['image'].shape, dataset_train['label'])\n",
    "        #print(dataset_train['label'])\n",
    "        x=Variable(dataset_train['image'], requires_grad=False)\n",
    "        y=Variable(dataset_train['label'])\n",
    "        x, y = x.cpu(), y.cpu()\n",
    "        if torch.cuda.is_available():\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            #print(\"Con cuda\")\n",
    "        output = net(x, False)\n",
    "        feature_dataset.append({\"label\": dataset_train['label'], \"feature\":output, \"name\": dataset_train['name']})\n",
    "\n",
    "    #Trasformiamo il tensor in una matrice\n",
    "    print(len(feature_dataset), len(feature_dataset[0]))\n",
    "    feature_dataset_matrix = np.zeros((len(feature_dataset), len(feature_dataset[0][\"feature\"][0])))\n",
    "    \n",
    "    #Qui abbiamo nelle righe tutte le immagini, nella lable feature tutte le 9000 colonne, ossia le feature.\n",
    "    print(len(feature_dataset), len(feature_dataset[0][\"feature\"][0]))\n",
    "    print(feature_dataset[0][\"label\"][0])\n",
    "    print(feature_dataset[1][\"label\"][0])\n",
    "\n",
    "    label_array = np.zeros(len(feature_dataset))\n",
    "    for i in range(0, len(feature_dataset)):#302\n",
    "        for j in range(0, len(feature_dataset[0][\"feature\"][0])):#9206\n",
    "            if j == 0:#salviamo la y finale nella colonna 0 della riga x.\n",
    "                #feature_dataset_matrix[j][i] = feature_dataset[j]['label'][0]\n",
    "                label_array[i] = feature_dataset[i]['label'][0]\n",
    "                print(i, end= \" \")\n",
    "            #else:\n",
    "            #print( i, j, end=\" \")\n",
    "            #Qua le estsrapoliamo DALLa LABEL feature e le sistemiamo in una matrice da dare in input al knn.\n",
    "            feature_dataset_matrix[i][j] =feature_dataset[i][\"feature\"][0][j] \n",
    "\n",
    "    print(len(feature_dataset_matrix), len(feature_dataset_matrix[0]), len(label_array))\n",
    "    print(feature_dataset[0][\"feature\"][0])\n",
    "    return feature_dataset_matrix, label_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302 3\n",
      "302 9216\n",
      "tensor(43)\n",
      "tensor(32)\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 9216 302\n",
      "tensor([0.0062, 0.0064, 0.0039,  ..., 0.0000, 0.0000, 0.0000], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "knn_1 = KNN(n_neighbors=1)\n",
    "if torch.cuda.is_available():\n",
    "    net = net.cuda()\n",
    "    torch.cuda.empty_cache()\n",
    "net.eval()\n",
    "input_for_datafram_train, label_array_train = GetInputForDataframe(barilla_train_loader, net)\n",
    "\n",
    "df = pd.DataFrame(input_for_datafram_train)\n",
    "#print(label_array[0], df.drop(0, axis = 1))\n",
    "knn_1.fit(df, label_array_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prendiamo le feature di una riga di test:\n",
    "feature_test = []\n",
    "for i, dataset_test in enumerate(barilla_test_loader):\n",
    "    if i == 129:\n",
    "        x=Variable(dataset_test['image'], requires_grad=False)\n",
    "        y=Variable(dataset_test['label'])\n",
    "        if torch.cuda.is_available():\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            #print(\"Con cuda\")\n",
    "        feature_test_0 = {\"feature\": net(x, False), \"class\": dataset_test['label']}\n",
    "    #print(dataset_test['label'])\n",
    "    x=Variable(dataset_test['image'], requires_grad=False)\n",
    "    y=Variable(dataset_test['label'])\n",
    "    if torch.cuda.is_available():\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        #print(\"Con cuda\")\n",
    "        #Questo è un vettore, facciamo di 0 perchè le altre voci non ci interessano al momento.\n",
    "    feature_test.append({\"feature\": net(x, False), \"class\": dataset_test['label']})\n",
    "#Proviamo la predizione\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302 302\n",
      "[8.]\n",
      "8.0  - real --> tensor([129])\n"
     ]
    }
   ],
   "source": [
    "#knn_1.fit(df, label_array_train)\n",
    "z = knn_1.predict(feature_test[8][\"feature\"].cpu().detach().numpy().reshape(1, -1))\n",
    "print(len(df.drop(0, axis = 1)), len(df[0]))\n",
    "print(z)\n",
    "print(z[0] , \" - real -->\", feature_test_0[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pandas as pd\\nfrom sklearn.neighbors import KNeighborsClassifier as KNN\\nknn_1 = KNN(n_neighbors=1)\\ninput_for_datafram_test, label_array_input = GetInputForDataframe(barilla_test_loader, net)\\ndf = pd.DataFrame(input_for_datafram_test)\\n#print(label_array[0], df.drop(0, axis = 1))\\nknn_1.fit(df, label_array)\\n#Prendiamo le feature di una riga di test:\\nfeature_test = []\\nfor i, dataset_test in enumerate(barilla_test_loader):\\n    #if i == 129:\\n    #print(dataset_test[\\'label\\'])\\n    x=Variable(dataset_test[\\'image\\'], requires_grad=False)\\n    y=Variable(dataset_test[\\'label\\'])\\n    #if torch.cuda.is_available():\\n        #x, y = x.cuda(), y.cuda()\\n        #print(\"Con cuda\")\\n    feature_test_0 = net(x, False)\\n    feature_test.append(net(x, False)[0])\\n#Proviamo la predizione\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NB: Guardare per bene i nomi, probabilmente c'è qualche errore e decommentare nei vari posti il torch.cuda.is_available.\n",
    "'''\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "knn_1 = KNN(n_neighbors=1)\n",
    "input_for_datafram_test, label_array_input = GetInputForDataframe(barilla_test_loader, net)\n",
    "df = pd.DataFrame(input_for_datafram_test)\n",
    "#print(label_array[0], df.drop(0, axis = 1))\n",
    "knn_1.fit(df, label_array)\n",
    "#Prendiamo le feature di una riga di test:\n",
    "feature_test = []\n",
    "for i, dataset_test in enumerate(barilla_test_loader):\n",
    "    #if i == 129:\n",
    "    #print(dataset_test['label'])\n",
    "    x=Variable(dataset_test['image'], requires_grad=False)\n",
    "    y=Variable(dataset_test['label'])\n",
    "    #if torch.cuda.is_available():\n",
    "        #x, y = x.cuda(), y.cuda()\n",
    "        #print(\"Con cuda\")\n",
    "    feature_test_0 = net(x, False)\n",
    "    feature_test.append(net(x, False)[0])\n",
    "#Proviamo la predizione\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy sul training set: %0.2f\" % knn_1.score(df, label_array))\n",
    "print(\"Accuracy sul test set: %0.2f\" % knn_1.score(data_test.drop('C',axis=1), data_test.C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from torch.optim import SGD\n",
    "from torch.autograd import Variable\n",
    "#Questa è la funzione per i dataset classici.\n",
    "def train_classification_special(model, lr=0.01, epochs=20, momentum=0.9, \\\n",
    "    train_loader=mnist_train_loader, test_loader=mnist_test_loader):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = SGD(model.parameters(),lr, momentum=momentum)\n",
    "    loaders = {'train':train_loader, 'test':test_loader}\n",
    "    losses = {'train':[], 'test':[]}\n",
    "    accuracies = {'train':[], 'test':[]}\n",
    "    if torch.cuda.is_available():\n",
    "        model=model.cuda()\n",
    "    for e in range(epochs):\n",
    "        print(\"Primo ciclo for.\")\n",
    "        for mode in ['train', 'test']:\n",
    "            print(\"Secondo ciclo for.\")\n",
    "            if mode=='train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            epoch_loss = 0\n",
    "            epoch_acc = 0\n",
    "            samples = 0\n",
    "            print(\"Mode-->\",mode)\n",
    "            print(\"Enumerate-->\", loaders[mode])\n",
    "            for i, batch in enumerate(loaders[mode]):\n",
    "                #trasformiamo i tensori in variabili\n",
    "                x=Variable(batch[0], requires_grad=(mode=='train'))\n",
    "                #print(\"x shape-->\",x.shape)\n",
    "                y=Variable(batch[1])\n",
    "                if torch.cuda.is_available():\n",
    "                    x, y = x.cuda(), y.cuda()\n",
    "                output = model(x)\n",
    "                l = criterion(output,y)\n",
    "                if mode=='train':\n",
    "                    l.backward()\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                print(\"L-->\",l.item())\n",
    "                acc = accuracy_score(y.cpu().data,output.cpu().max(1)[1].data)\n",
    "                epoch_loss+=l.data.item()*x.shape[0]\n",
    "                epoch_acc+=acc*x.shape[0]\n",
    "                samples+=x.shape[0]\n",
    "                print (\"\\r[%s] Epoch %d/%d. Iteration %d/%d. Loss: %0.2f. Accuracy: %0.2f\\t\\t\\t\\t\\t\" % \\\n",
    "                (mode, e+1, epochs, i, len(loaders[mode]), epoch_loss/samples, epoch_acc/samples),\n",
    "                epoch_loss/samples,\n",
    "                epoch_acc/samples,\n",
    "                losses[mode].append(epoch_loss))\n",
    "                accuracies[mode].append(epoch_acc)\n",
    "            print(\"Fine secondo ciclo for\")\n",
    "        print(\"\\r[%s] Epoch %d/%d. Iteration %d/%d. Loss: %0.2f. Accuracy: %0.2f\\t\\t\\t\\t\\t\" % \\\n",
    "        (mode, e+1, epochs, i, len(loaders[mode]), epoch_loss, epoch_acc))\n",
    "\n",
    "    print(\"Ho finito.\")\n",
    "    #restituiamo il modello e i vari log\n",
    "    return model, (losses, accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "# Created by: BoyuanJiang\n",
    "# College of Information Science & Electronic Engineering,ZheJiang University\n",
    "# Email: ginger188@gmail.com\n",
    "# Copyright (c) 2017\n",
    "\n",
    "# @Time    :17-8-27 21:25\n",
    "# @FILE    :matching_networks.py\n",
    "# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def convLayer(in_channels, out_channels, keep_prob=0.0):\n",
    "    \"\"\"3*3 convolution with padding,ever time call it the output size become half\"\"\"\n",
    "    cnn_seq = nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "        nn.ReLU(True),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Dropout(keep_prob)\n",
    "    )\n",
    "    return cnn_seq\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, layer_size=64, num_channels=1, keep_prob=1.0, image_size=28):\n",
    "        super(Classifier, self).__init__()\n",
    "        \"\"\"\n",
    "        Build a CNN to produce embeddings\n",
    "        :param layer_size:64(default)\n",
    "        :param num_channels:\n",
    "        :param keep_prob:\n",
    "        :param image_size:\n",
    "        \"\"\"\n",
    "        self.layer1 = convLayer(num_channels, layer_size, keep_prob)\n",
    "        self.layer2 = convLayer(layer_size, layer_size, keep_prob)\n",
    "        self.layer3 = convLayer(layer_size, layer_size, keep_prob)\n",
    "        self.layer4 = convLayer(layer_size, layer_size, keep_prob)\n",
    "\n",
    "        finalSize = int(math.floor(image_size / (2 * 2 * 2 * 2)))\n",
    "        self.outSize = finalSize * finalSize * layer_size\n",
    "\n",
    "    def forward(self, image_input):\n",
    "        \"\"\"\n",
    "        Use CNN defined above\n",
    "        :param image_input:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        x = self.layer1(image_input)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class AttentionalClassify(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AttentionalClassify, self).__init__()\n",
    "\n",
    "    def forward(self, similarities, support_set_y):\n",
    "        \"\"\"\n",
    "        Products pdfs over the support set classes for the target set image.\n",
    "        :param similarities: A tensor with cosine similarites of size[batch_size,sequence_length]\n",
    "        :param support_set_y:[batch_size,sequence_length,classes_num]\n",
    "        :return: Softmax pdf shape[batch_size,classes_num]\n",
    "        \"\"\"\n",
    "        softmax = nn.Softmax()\n",
    "        softmax_similarities = softmax(similarities)\n",
    "        preds = softmax_similarities.unsqueeze(1).bmm(support_set_y).squeeze()\n",
    "        return preds\n",
    "\n",
    "\n",
    "class DistanceNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    This model calculates the cosine distance between each of the support set embeddings and the target image embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DistanceNetwork, self).__init__()\n",
    "\n",
    "    def forward(self, support_set, input_image):\n",
    "        \"\"\"\n",
    "        forward implement\n",
    "        :param support_set:the embeddings of the support set images.shape[sequence_length,batch_size,64]\n",
    "        :param input_image: the embedding of the target image,shape[batch_size,64]\n",
    "        :return:shape[batch_size,sequence_length]\n",
    "        \"\"\"\n",
    "        eps = 1e-10\n",
    "        similarities = []\n",
    "        for support_image in support_set:\n",
    "            sum_support = torch.sum(torch.pow(support_image, 2), 1)\n",
    "            support_manitude = sum_support.clamp(eps, float(\"inf\")).rsqrt()\n",
    "            dot_product = input_image.unsqueeze(1).bmm(support_image.unsqueeze(2)).squeeze()\n",
    "            cosine_similarity = dot_product * support_manitude\n",
    "            similarities.append(cosine_similarity)\n",
    "        similarities = torch.stack(similarities)\n",
    "        return similarities.t()\n",
    "\n",
    "\n",
    "class BidirectionalLSTM(nn.Module):\n",
    "    def __init__(self, layer_size, batch_size, vector_dim,use_cuda):\n",
    "        super(BidirectionalLSTM, self).__init__()\n",
    "        \"\"\"\n",
    "        Initial a muti-layer Bidirectional LSTM\n",
    "        :param layer_size: a list of each layer'size\n",
    "        :param batch_size: \n",
    "        :param vector_dim: \n",
    "        \"\"\"\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_size = layer_size[0]\n",
    "        self.vector_dim = vector_dim\n",
    "        self.num_layer = len(layer_size)\n",
    "        self.use_cuda = use_cuda\n",
    "        self.lstm = nn.LSTM(input_size=self.vector_dim, num_layers=self.num_layer, hidden_size=self.hidden_size,\n",
    "                            bidirectional=True)\n",
    "        self.hidden = self.init_hidden(self.use_cuda)\n",
    "\n",
    "    def init_hidden(self,use_cuda):\n",
    "        if use_cuda:\n",
    "            return (Variable(torch.zeros(self.lstm.num_layers * 2, self.batch_size, self.lstm.hidden_size),requires_grad=False).cuda(),\n",
    "                    Variable(torch.zeros(self.lstm.num_layers * 2, self.batch_size, self.lstm.hidden_size),requires_grad=False).cuda())\n",
    "        else:\n",
    "            return (Variable(torch.zeros(self.lstm.num_layers * 2, self.batch_size, self.lstm.hidden_size),requires_grad=False),\n",
    "                    Variable(torch.zeros(self.lstm.num_layers * 2, self.batch_size, self.lstm.hidden_size),requires_grad=False))\n",
    "\n",
    "    def repackage_hidden(self,h):\n",
    "        \"\"\"Wraps hidden states in new Variables, to detach them from their history.\"\"\"\n",
    "        if type(h) == Variable:\n",
    "            return Variable(h.data)\n",
    "        else:\n",
    "            return tuple(self.repackage_hidden(v) for v in h)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # self.hidden = self.init_hidden(self.use_cuda)\n",
    "        self.hidden = self.repackage_hidden(self.hidden)\n",
    "        output, self.hidden = self.lstm(inputs, self.hidden)\n",
    "        return output\n",
    "\n",
    "\n",
    "class MatchingNetwork(nn.Module):\n",
    "    def __init__(self, keep_prob=0.0, batch_size=32, num_channels=1, learning_rate=1e-3, fce=False, num_classes_per_set=20, \\\n",
    "                 num_samples_per_class=1, image_size=28, use_cuda=True):\n",
    "        \"\"\"\n",
    "        This is our main network\n",
    "        :param keep_prob: dropout rate\n",
    "        :param batch_size:\n",
    "        :param num_channels:\n",
    "        :param learning_rate:\n",
    "        :param fce: Flag indicating whether to use full context embeddings(i.e. apply an LSTM on the CNN embeddings)\n",
    "        :param num_classes_per_set:\n",
    "        :param num_samples_per_class:\n",
    "        :param image_size:\n",
    "        \"\"\"\n",
    "        super(MatchingNetwork, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.keep_prob = keep_prob\n",
    "        self.num_channels = num_channels\n",
    "        self.learning_rate = learning_rate\n",
    "        self.fce = fce\n",
    "        self.num_classes_per_set = num_classes_per_set\n",
    "        self.num_samples_per_class = num_samples_per_class\n",
    "        self.image_size = image_size\n",
    "        self.g = Classifier(layer_size=64, num_channels=num_channels, keep_prob=keep_prob, image_size=image_size)\n",
    "        self.dn = DistanceNetwork()\n",
    "        self.classify = AttentionalClassify()\n",
    "        if self.fce:\n",
    "            self.lstm = BidirectionalLSTM(layer_size=[32], batch_size=self.batch_size, vector_dim=self.g.outSize,use_cuda=use_cuda)\n",
    "\n",
    "    def forward(self, support_set_images, support_set_y_one_hot, target_image, target_y):\n",
    "        \"\"\"\n",
    "        Main process of the network\n",
    "        :param support_set_images: shape[batch_size,sequence_length,num_channels,image_size,image_size]\n",
    "        :param support_set_y_one_hot: shape[batch_size,sequence_length,num_classes_per_set]\n",
    "        :param target_image: shape[batch_size,num_channels,image_size,image_size]\n",
    "        :param target_y:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # produce embeddings for support set images\n",
    "        encoded_images = []\n",
    "        for i in np.arange(support_set_images.size(1)):\n",
    "            gen_encode = self.g(support_set_images[:, i, :, :])\n",
    "            encoded_images.append(gen_encode)\n",
    "\n",
    "        # produce embeddings for target images\n",
    "        gen_encode = self.g(target_image)\n",
    "        encoded_images.append(gen_encode)\n",
    "        output = torch.stack(encoded_images)\n",
    "\n",
    "        # use fce?\n",
    "        if self.fce:\n",
    "            outputs = self.lstm(output)\n",
    "\n",
    "        # get similarities between support set embeddings and target\n",
    "        similarites = self.dn(support_set=output[:-1], input_image=output[-1])\n",
    "\n",
    "        # produce predictions for target probabilities\n",
    "        preds = self.classify(similarites, support_set_y=support_set_y_one_hot)\n",
    "\n",
    "        # calculate the accuracy\n",
    "        values, indices = preds.max(1)\n",
    "        accuracy = torch.mean((indices.squeeze() == target_y).float())\n",
    "        crossentropy_loss = F.cross_entropy(preds, target_y.long())\n",
    "\n",
    "        return accuracy, crossentropy_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_network = MatchingNetwork()\n",
    "lenet_mnist_predictions, lenet_mnist_gt = train_classification(matching_network)\n",
    "print (\"Accuracy LeNet su DIGITS: %0.2f\" % \\\n",
    "accuracy_score(lenet_mnist_gt,lenet_mnist_predictions.argmax(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
